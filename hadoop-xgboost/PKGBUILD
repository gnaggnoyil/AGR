# Maintainer: Yonggang Li <gnaggnoyil@gmail.com>
# Contributor: William Tang <galaxyking0419@gmail.com>
# Contributor: Chris Severance <aur.severach@spamgourmet.com>
# Contributor: David Roheim <david.roheim@gmail.com>
# Contributor: Manuel Hoffmann <manuel@manuel-hoffmann.info>
# Contributor: Markus Holtermann <aur@markusholtermann.eu>
# Contributor: Mantas Vidutis <mantas.a.vidutis-at-gmail.com>
# Contributor: Tianjiao Yin <ytj000@gmail.com>

# `namcap` seems to be reporting missing `java-runtime` dependency if it founds
# jar files even if those jar files relies on java-runtime-headless-openjdk
# only. Should we open an issue for namcap?

set -u
_pkgbasename=hadoop
pkgname=${_pkgbasename}-xgboost
pkgver=3.3.4
pkgrel=3
pkgdesc='An open-source software for reliable, scalable, distributed computing (built for xgboost)'
arch=('i686' 'x86_64')
url='https://hadoop.apache.org'
license=('apache')
provides=("${_pkgbasename}")
# `provides` and `conflicts` are two different options
conflicts=("${_pkgbasename}")
makedepends=('cmake' 'gcc' 'java-environment<=11' 'make' 'maven')
depends=('inetutils' 'java-runtime-headless-openjdk=11' 'openssh' 'protobuf')
source=(
    "https://github.com/apache/${_pkgbasename}/archive/refs/tags/rel/release-${pkgver}.tar.gz"
    "${_pkgbasename}-conf"
    "${_pkgbasename}-profile.sh"
    "${_pkgbasename}-datanode.service"
    "${_pkgbasename}-historyserver.service"
    "${_pkgbasename}-namenode.service"
    "${_pkgbasename}-resourcemanager.service"
    "${_pkgbasename}-secondarynamenode.service"
)
sha256sums=('a10fb474084c5d38b93ae901b453794d668ca98aa419a0546807b10cdae17827'
            '86adb9d28c5240023950339943e8d63bee91a99a18431699a8fb4839ee2a3b61'
            'f9495f39dfdda1b976ad26c5973f65755f086690cf4cfc9eee33060aac8205d2'
            'c6834f1355a0c40c7ccb6ac8813637ec78de05835015665cd9ed1f6d0470e716'
            'b0d28212273e24409659c195ce57793c3ce536683559be13dd4a00d72ca01913'
            '9e16d9a3ebb7a08c1a00083c9a6de6e93f17f4c7911f1e5a8f7630fa42f6fcd7'
            'f8d2f186fa14a5f8a81434eeac52b20b5f1d5dd9a3d4fd845490b8cb0bba7e73'
            '33c60198c2982a2d05a148f89c7722efcb571b04ea8e971715e107d150e4dbb8')
install=${pkgname}.install
backup=(
    "etc/conf.d/${_pkgbasename}"
    "etc/profile.d/${_pkgbasename}"
    "etc/${_pkgbasename}/capacity-scheduler.xml"
    # Should this file put in the backup?
    "etc/${_pkgbasename}/configuration.xsl"
    "etc/${_pkgbasename}/container-executor.cfg"
    "etc/${_pkgbasename}/core-site.xml"
    "etc/${_pkgbasename}/hadoop-env.sh"
    "etc/${_pkgbasename}/hadoop-metrics2.properties"
    "etc/${_pkgbasename}/hadoop-policy.xml"
    "etc/${_pkgbasename}/hdfs-rbf-site.xml"
    "etc/${_pkgbasename}/hdfs-site.xml"
    "etc/${_pkgbasename}/httpfs-env.sh"
    "etc/${_pkgbasename}/httpfs-log4j.properties"
    "etc/${_pkgbasename}/httpfs-site.xml"
    "etc/${_pkgbasename}/kms-acls.xml"
    "etc/${_pkgbasename}/kms-env.sh"
    "etc/${_pkgbasename}/kms-log4j.properties"
    "etc/${_pkgbasename}/kms-site.xml"
    "etc/${_pkgbasename}/log4j.properties"
    "etc/${_pkgbasename}/mapred-env.sh"
    "etc/${_pkgbasename}/mapred-site.xml"
    "etc/${_pkgbasename}/workers"
    "etc/${_pkgbasename}/yarn-env.sh"
    "etc/${_pkgbasename}/yarnservice-log4j.properties"
    "etc/${_pkgbasename}/yarn-site.xml"
)

build() {
    set -u
    export JAVA_HOME=/usr/lib/jvm/java-11-openjdk
    cd "${srcdir}/${_pkgbasename}-rel-release-${pkgver}"
    mvn package -Pdist,native -Drequire.openssl -Drequire.zstd -Dmaven.javadoc.skip=true -DskipTests
    set +u
}

package() {
    set -u
    
    mkdir -p "${pkgdir}/usr/lib"
    cp -pr "${srcdir}/${_pkgbasename}-rel-release-${pkgver}/hadoop-dist/target/${_pkgbasename}-${pkgver}" "${pkgdir}/usr/lib"
    cd "${pkgdir}/usr/lib"
    ln -s "${_pkgbasename}-${pkgver}" "${_pkgbasename}"

    # Remove windows batch files
    cd "${pkgdir}/usr/lib/${_pkgbasename}-${pkgver}"
    rm {etc/hadoop,bin,sbin,share/hadoop/tools/resourceestimator/bin}/*.cmd

    install -Dpm755 "${srcdir}/${_pkgbasename}-conf" "${pkgdir}/etc/conf.d/${_pkgbasename}"
    install -Dpm755 "${srcdir}/${_pkgbasename}-profile.sh" "${pkgdir}/etc/profile.d/${_pkgbasename}.sh"
    for srv in datanode historyserver namenode resourcemanager secondarynamenode; do
        install -Dpm644 "${srcdir}/${_pkgbasename}-${srv}.service" -t "${pkgdir}/usr/lib/systemd/system"
    done

    # We do not use soft link because we need to put configures in backup array,
    # in order to preserve the conf when upgrading package.
    cp -pr "${pkgdir}/usr/lib/${_pkgbasename}-${pkgver}/etc/hadoop" "${pkgdir}/etc"
    rm -rf "${pkgdir}/usr/lib/${_pkgbasename}-${pkgver}/etc/hadoop"
    rm -d "${pkgdir}/usr/lib/${_pkgbasename}-${pkgver}/etc"

    mkdir -p "${pkgdir}/usr/bin"
    # Wrapper script instead of a simple soft link is required since hadoop
    # sometimes uses its own executable location to calculate HADOOP_HOME
    install -Dm755 <(cat << EOF
#!/bin/sh
# Automatically generated by ${pkgname}-${pkgver} PKGBUILD
/usr/lib/hadoop-${pkgver}/bin/hadoop "\$@"
EOF
    ) "${pkgdir}/usr/bin/hadoop"

    mkdir -p "${pkgdir}/var/lib/hadoop"
    mkdir -p "${pkgdir}/var/log/hadoop"

    # Move license and notice files
    mkdir -p "${pkgdir}/usr/share/licenses/${pkgname}"
    cd "${pkgdir}/usr/lib/${_pkgbasename}-${pkgver}"
    mv licenses-binary/* LICENSE* NOTICE* README.txt "${pkgdir}/usr/share/licenses/${pkgname}/"

    set +u
}
set +u
